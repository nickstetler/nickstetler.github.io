<!DOCTYPE html>
<html lang="en">    
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <title>Nicholas Stetler</title>
    <style>
body {
    font-family: Georgia, serif;
    line-height: 1.7;
    max-width: 800px;
    margin: 40px auto;
    padding: 20px;
}

h1, h2 {
    font-family: Georgia, serif;
    font-weight: bold;
}

h1 {
    font-size: 28px;
}

h2 {
    font-size: 24px;
    border-bottom: 2px solid #ccc;
    padding-bottom: 5px;
}

p {
    font-size: 18px;
}
    </style>
</head>
    <section id="about">
        <h1>About me</h1>
        <p>I am a law student interested in computers, old books, and public policy.</p>
    </section>
     <section id="blog">
         <h1>Blog</h1>
<body>
<h3>From Soul to Self to Niche: Rethinking Who We Are</h3>

<p>We are told to “find ourselves.” But what if that search begins in the wrong place?</p>

<p>What if the self isn’t hidden deep inside, waiting to be uncovered through introspection or self-expression—but something that emerges from the <em>outside in</em>? What if you are not who you privately feel yourself to be, but who you are <em>called</em> to be—<em>not</em> essence, but <strong>alignment</strong>?</p>

<p>One of the through-lines in Peter Watson’s <em>From Fire to Freud</em> is precisely this evolving conception of the individual—from ancient ideas of the soul, through Enlightenment accounts of the mind, to the emergence of the modern psychological self. What I want to suggest is that this trajectory doesn’t stop there. There’s another stage forming in our cultural unconscious—one Watson hints at but doesn’t name. I’ll call it the <strong>niche</strong>.</p>

<p>This post is about that next move: from <strong>soul</strong>, to <strong>self</strong>, to <strong>niche</strong>. From metaphysical interiority to ecological embeddedness. From introspection to <strong>fit</strong>.</p>

<h4>Identity as Role, Not Essence</h4>

<p>In biology, a niche is not an object or a possession. It is a pattern of relations: a functional position within a living system. A species’ niche is its mode of life—how it makes use of its environment, how it contributes to and depends upon others, how it plays a role in sustaining a larger whole.</p>

<p>What if human identity works the same way?</p>

<p>What if you are not your preferences or your personality, but your <em>place</em>? What if who you are is best understood not by looking inward, but by asking: what role are you called to inhabit? What form of life are you particularly suited for—structurally, morally, spiritually?</p>

<p>Your identity, on this model, is not something you choose. It is something you <em>answer</em> to. The niche is not expressive. It is <strong>vocational</strong>.</p>

<h4>The Soul, the Self, and the Niche</h4>

<p>Western thought has long centered on interiority. In the classical and Christian traditions, the <strong>soul</strong> is the immortal center of personhood: non-material, moral, divinely imprinted. In modernity, the <strong>self</strong> takes on new psychological dimensions: autonomous, introspective, self-fashioning. Each concept moves the source of identity deeper within the subject.</p>

<p>But in the niche framework, that trajectory reverses. The self is not a private interiority—it is a <strong>public coordination</strong>. It is not found, but <em>fitted</em>. You are what you do, where you are, for the sake of what lies beyond you.</p>

<p>This isn’t just metaphor. It’s ontological. In ecology, an organism cannot be understood apart from its niche—it is always already <em>entangled</em> with its context. The same may be true for us.</p>

<h4>From Emptiness to Embeddedness</h4>

<p>Other traditions anticipated this. In Buddhist philosophy, the self is an illusion—a momentary configuration of causes and conditions. In Aquinas, the soul is not an interior ghost but the <em>form</em> of the body, oriented by its end, participating in a divine order. Even cyberpunk fiction, like <em>Ghost in the Shell</em>, imagines identity as distributed across networks, environments, and systems. These are all versions—spiritual, metaphysical, technological—of the same insight: the self is <strong>not self-contained</strong>.</p>

<p>And the niche, as I’m using it, is the contemporary distillation of this insight. It suggests that identity is not something we <em>express</em>, but something we <em>inhabit</em>. That we are not selves first and then find our place, but that we are shaped into persons <em>through</em> our place.</p>

<h4>The Language of Sin and Sanctification</h4>

<p>This brings us to a theological inflection. Because if we take this idea seriously, it carries profound moral weight.</p>

<p>There is a word for misalignment between who you are and what you are called to do: <strong>sin</strong>.</p>

<p>Sin is not merely the violation of a rule. It is the refusal to fulfill a role. It is resistance to the form you were made for. To live outside your niche is to live in disorder—not just moral disorder, but ontological disorder. You become unmoored. You drift. You act, but without participation in the good.</p>

<p>Conversely, to live rightly is to live <em>in your niche</em>. To respond, not react. To accept your placement—not as passive resignation, but as <strong>the site of your becoming</strong>. Holiness is not freedom from constraints. It is fidelity to the right constraints. It is the peace that comes from belonging rightly.</p>

<h4>You Are Where You Are Called to Be</h4>

<p>If the soul was the place of divine imprint, and the self the theater of expression, then the niche is the <strong>site of obedience</strong>.</p>

<p>It is where your gifts meet the world’s need. It is where your limitations meet divine sufficiency. It is where you are neither your own nor lost in the crowd, but <strong>responsible</strong>—in the deepest, oldest sense of the word.</p>

<p>In this framework, you don’t “find yourself.” You <em>answer</em>. You don’t invent a purpose. You <em>receive</em> one. And the degree to which you live in that calling is the degree to which you are <em>truly</em> yourself—not the self you imagine, but the self you were made to be.</p>

<p>The good news is that this calling is not fragile. It does not depend on clarity or success. Even those who stray from their niche can be <em>grafted back in</em>. Even dislocation can become a path of return. There is no place so lost that the right name cannot call it home.</p>

<p><strong>You are what you ought to do.</strong><br>
And what you ought to do is already whispering your name.<br>
You do not need to invent your identity.<br>
You need only to listen—and follow.</p>

    <h3>Brief of my Law Journal Note: Reinsurance as Scalable Governance for Frontier AI Risk </h3>
    <p><strong>Author:</strong> Nicholas A. Stetler, JD Candidate 2026, SIU Simmons Law</p>

    <h5>Overview</h5>
    <p>Frontier AI systems—especially large models with emergent capabilities or dual-use potential—pose catastrophic downside risks that existing regulatory frameworks are ill-equipped to manage. This brief proposes a targeted federal reinsurance program as a mechanism to support the growth of a private insurance market for high-risk AI, thereby transforming currently unmanageable uncertainty into structured, incentivized governance.</p>

    <h5>The Proposal</h5>
    <p>Congress should authorize a federally funded reinsurance scheme for insurers who underwrite AI developers working with the most dangerous AI systems. Modeled in part on the Price-Anderson Act (for nuclear energy) and the FDIC (for banking), this program would cap insurers' catastrophic exposure while preserving private sector judgment about underwriting and pricing.</p>
    <p>By absorbing tail risk, the federal government would allow insurers to offer meaningful coverage, and in doing so, exert pressure on developers to adopt safety practices, restrict certain behaviors, and disclose risk-related information. Insurers, in turn, would generate granular risk mappings through actuarial processes, exclusions, and coverage thresholds—information that regulators and the public could use to better understand the landscape of emerging AI hazards.</p>

    <h5>Why This Matters</h5>
    <ul>
        <li><strong>Targeted Governance:</strong> The program would apply only to systems that meet clear criteria for extreme capability or scale (e.g., SB 1047’s "frontier model" definition), avoiding overreach while addressing the most urgent class of risks.</li>
        <li><strong>Scalable & Incentive-Compatible:</strong> Unlike rigid command-and-control regimes, reinsurance works with market structures, producing a governance layer that adapts over time.</li>
        <li><strong>Knowledge Generation:</strong> The insurance underwriting process transforms unknown unknowns into quantifiable liabilities, aiding the broader project of AI alignment and public safety.</li>
    </ul>

    <h5>Strategic Rationale</h5>
    <p>Well-designed insurance markets can do more than compensate for loss—they can shape behavior upstream by influencing which practices are insurable and which are excluded. Federally backed reinsurance catalyzes this market where private actors would otherwise be unwilling to bear systemic risk alone. By focusing narrowly on frontier systems, the program ensures clarity, minimizes administrative burden, and builds an initial testbed for broader AI governance mechanisms.</p>

    <h5>Conclusion</h5>
    <p>Just as the insurance revolution enabled empire-building exploration and industrial risk-taking in earlier eras, reinsurance for high-risk AI could serve as a 21st-century governance foundation. By linking safety incentives to insurability and enabling risk assessment at scale, a targeted federal reinsurance program offers a pragmatic, adaptive, and forward-compatible approach to regulating the most dangerous AI systems.</p>

    <h3>Conclusion I wanted to write for my reinsurance paper</h3> 
    <p>I had so much fun writing this for my conclusion that I can't bear to throw it out. Unfortunately, I can't use it because it is nowhere near the appropriate tone.</p>
    <p>Perhaps we stand today where the world once stood before the steam engine turned its first wheel, before the atom split, before the first bulb flickered on in the darkness.</p>
    
    <p>There was a time, not so long ago, when another frontier beckoned. A time when vast fortunes were wagered on what lay beyond the horizon. The Age of Exploration was not born from curiosity alone—it was born from risk, and from the need to manage it. When the great powers of Europe set their ships toward unknown waters, they did so not blindly, but backed by something new: Insurance.</p>
    
    <p>Lloyd’s of London, rising from a coffeehouse filled with men who understood that the future belonged not to those who feared the storm, but to those who prepared for it. Policies written on parchment, staking gold on the gamble that a ship might return not shattered on the rocks, but laden with spice and silk, gold and silver. Insurance turned exploration from recklessness into strategy, from a fatal wager into an empire-building enterprise. It was not the compass or the sextant alone that carried men across the oceans—it was the knowledge that, should the worst happen, the risk had already been accounted for.</p>
    
    <p>And now, here we stand, staring at a new, uncharted ocean. The ghost in the machine is no longer a thought experiment. It is no longer theoretical. It is being built, here and now, by minds and machines operating at a speed the world has never seen. And just like the great voyages of the past, it carries risks that could shape, or shake, the foundations of civilization itself.</p>
    
    <p>History does not wait. It does not hesitate. It rewards those who prepare, and it punishes those who do not. And if we are to cross this next great ocean, there is no better preparation—nothing more proactive, nothing more prudent—than insurance.</p>
    
    <h3>What Robert Caro can teach us about AI governance</h3>
    
    <p>Over the past year I finally finished <em>The Power Broker</em> after rediscovering the joy of audiobooks. I listened to <em>Working</em> then moved through <em>The Years of Lyndon Johnson</em> (four volumes) in an odd order. I started with <em>Master of the Senate</em> (v.3), then moved to <em>The Path to Power</em> (v.1), then <em>The Passage of Power</em> (v.4), and finally <em>Means of Ascent</em> (v.2). I then went back over <em>Working</em>. I have now been working my way through Peter Watson’s two books on intellectual history, <em>Ideas: From Fire to Freud</em>, and <em>The Modern Mind</em>. I also just wrote a potted history of the Civil Rights movement and then a comparison of Kafka’s sense of alienation and the alienation of Black folks after the passage of the 1964 Civil Rights Act. Currently, I am working on my law journal note on reinsurance as a mechanism of AI governance, as getting AI right is really the great challenge of our time. I see a through-line between each of these topics that I will try to elaborate here.</p>
    
    <p>Robert Caro doesn’t just write biographies—he writes about power. His books aren’t just about Robert Moses or Lyndon Johnson; they’re about how things actually get done in America. If you want to change the world through policy, you need more than just good ideas. You need to understand how power moves through institutions and how to make it work for you. His work shows that successful policymaking depends on three key elements: first, substantively good policy—it has to work in the real world, not just look good on paper. Second, a compelling narrative—people need to believe in it, or it won’t go anywhere. And third, relentless realpolitik—you have to navigate bureaucracies, alliances, and opposition to make it happen.</p>
    
    <p>This framework isn’t just useful for looking at the past—it’s essential for thinking about the future, including how we govern artificial intelligence. AI is moving fast, and if we want to regulate it effectively, we need to apply the same lessons that Caro’s subjects mastered.</p>
    
    <p>First, a policy has to actually work. It has to be enforceable, clear, and designed to achieve real results. This sounds obvious, but you’d be surprised how many policies fail because they weren’t thought through at a technical level. Caro’s subjects understood this well. Robert Moses wrote policies so airtight that even his political enemies couldn’t undo them. He knew the legal and financial levers of power better than anyone. Lyndon Johnson, meanwhile, left the technical details to experts, but he made sure the policies he pushed had real-world impact. AI policy has to follow this approach. It needs to be technically precise—a vague liability law won’t stop AI risks. It has to be legally enforceable—rules that can’t be applied in practice are useless. And it must be aligned with incentives—if a policy goes against the interests of key players, they’ll find ways around it.</p>
    
    <p>But good policy isn’t enough. You also need a story that makes people care, a sticky why. Every major political movement has framed its policies within a broader vision. Ancient Rome had <em>Roma Eterna</em>—The Eternal Rome. The Soviet Union had <em>Seize the Means of Production!</em> The United States has the American Dream and The Great Society. Thinkers in the liberal/progressive tradition such as Locke, Rawls, and Arendt all understood that political legitimacy depends on people believing in the system. A policy without a strong narrative is just paperwork. AI regulation is no different. If it’s framed as blocking innovation, it will fail. If it’s framed as ensuring human control over powerful technology, it has a chance. The way policymakers talk about AI will shape how people react to regulation.</p>
    
    <p>Even if a policy is well-designed and has a great narrative, it still won’t pass on its own. Someone has to push it through, navigate resistance, and make it stick. Robert Moses was a master of bureaucracy—he used legal loopholes and bureaucratic authority to push through his projects. Lyndon Johnson understood people—he knew how to build coalitions, cut deals, and use pressure to get things done. AI policymakers need to apply these same lessons. They need to understand what politicians, businesses, and voters actually want. AI regulation won’t pass without buy-in from key players—tech companies, advocacy groups, and governments. Even the best AI policy will fail if it doesn’t fit into the real-world incentives of lawmakers.</p>
    
    <p>Big policy changes often disrupt existing narratives, which can lead to backlash. Caro shows how leaders who changed the system had to manage these disruptions carefully. Kafka’s world feels like a bureaucratic nightmare—laws change, but people still feel powerless. This isn’t so different from the post-Civil Rights era, where the legal landscape changed, but people’s lived experiences didn’t always follow immediately. AI is going to change society in unpredictable ways, and that can create backlash. If AI-generated content dominates books, movies, and art, will people still see it as real? Policymakers need to be ahead of the curve in managing public reaction to AI.</p>
    
    <p>The lessons from Caro’s books apply directly to AI governance. AI regulations need to be clear and enforceable. AI governance must be framed in a way that resonates with the public. Policymakers need to understand power dynamics to get AI laws passed. Robert Moses knew that the technical side of policy is critical, but so is shaping the bureaucracy to implement it. Lyndon Johnson understood that a strong vision is important, but execution matters just as much. And Kafka’s world reminds us that big shifts in technology and policy create societal disorientation—ignoring this leads to backlash.</p>
    
    <p>Policymakers need to recognize that good ideas alone aren’t enough. To succeed, AI policy must be:</p>
    <ul>
        <li><strong>Technically effective</strong>—it must work in practice, not just in theory.</li>
        <li><strong>Politically persuasive</strong>—it must be framed in a way that makes sense to people.</li>
        <li><strong>Strategically implemented</strong>—it must navigate the realities of government, business, and society.</li>
    </ul>
    
    <p>If AI policy is going to succeed, it needs the same mix of technical know-how, compelling vision, and strategic execution that Caro’s subjects used to reshape the world. The future of AI governance depends on policymakers who understand not just the technology, but the politics of making real change happen.</p>
</body>
    <section id="Contact">
        <h1>Contact</h1>
        <p>nickstetler@gmail</p>
    </section>
    <section>
        <h1>Curriculum Vitæ</h1>
         <a href="CV_NICHOLAS_STETLER.pdf" target="_blank">Curriculum Vitæ</a>
    </section>
</html>
